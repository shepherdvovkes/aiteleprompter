/**
 * Audio Capture Module for Interview Assistant
 * Captures audio from VB Cable (P1) and Microphone (P2)
 */

class AudioCapture {
    constructor() {
        this.isCapturing = false;
        this.ws = null;
        this.mediaRecorder = null;
        this.audioContext = null;
        this.micStream = null;
        this.vbCableStream = null;
        this.recordingChunks = [];
        
        // Audio processing parameters
        this.chunkDuration = 1000; // 1 second chunks
        this.sampleRate = 44100;
        
        // Audio level analysis
        this.p1Analyser = null;
        this.p2Analyser = null;
        this.p1DataArray = null;
        this.p2DataArray = null;
        this.currentLevels = { p1: 0, p2: 0 };
        this.continuousMonitorInterval = null;
        
        this.initializeWebSocket();
    }

    async initializeWebSocket() {
        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const wsUrl = `${protocol}//${window.location.host}`;
        
        this.ws = new WebSocket(wsUrl);
        
        this.ws.onopen = () => {
            console.log('Audio capture connected to server');
            this.ws.send(JSON.stringify({ type: 'set-person', person: 'capture-client' }));
        };
        
        this.ws.onmessage = (event) => {
            const data = JSON.parse(event.data);
            this.handleServerMessage(data);
        };
        
        this.ws.onclose = () => {
            console.log('Audio capture disconnected from server');
            setTimeout(() => this.initializeWebSocket(), 3000);
        };
    }

    handleServerMessage(data) {
        switch (data.type) {
            case 'recording-started':
                this.startCapture();
                break;
            case 'recording-stopped':
                this.stopCapture();
                break;
        }
    }

    async startCapture() {
        if (this.isCapturing) return;
        
        try {
            this.isCapturing = true;
            console.log('Starting audio capture...');
            
            // Start microphone capture (P2)
            await this.startMicrophoneCapture();
            
            // Start VB Cable capture (P1) - if available
            await this.startVBCableCapture();
            
            console.log('Audio capture started successfully');
        } catch (error) {
            console.error('Error starting audio capture:', error);
            this.isCapturing = false;
        }
    }

    async startMicrophoneCapture() {
        try {
            // Request microphone access
            this.micStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: false,
                    noiseSuppression: false,
                    autoGainControl: false,
                    sampleRate: this.sampleRate,
                    channelCount: 1
                }
            });

            this.setupAudioRecording(this.micStream, 'P2');
            console.log('Microphone capture started (P2)');
            
        } catch (error) {
            console.error('Error accessing microphone:', error);
            throw error;
        }
    }

    async startVBCableCapture() {
        try {
            console.log('–ù–∞—á–∏–Ω–∞—é –ø–æ–∏—Å–∫ VB Cable —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞...');
            
            // Try to get VB Cable device
            const devices = await navigator.mediaDevices.enumerateDevices();
            console.log('–ù–∞–π–¥–µ–Ω–æ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤:', devices.length);
            
            // Log all audio input devices for debugging
            const audioInputs = devices.filter(device => device.kind === 'audioinput');
            console.log('–ê—É–¥–∏–æ –≤—Ö–æ–¥–Ω—ã–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:');
            audioInputs.forEach((device, index) => {
                console.log(`${index + 1}. ${device.label} (ID: ${device.deviceId.substring(0, 20)}...)`);
            });
            
            // More specific VB Cable detection to avoid false positives
            const vbCableDevice = devices.find(device => 
                device.kind === 'audioinput' && 
                (device.label.toLowerCase().includes('vb-audio') ||
                 device.label.toLowerCase().includes('vb cable') ||
                 device.label.toLowerCase().includes('vbcable') ||
                 device.label.toLowerCase().includes('virtual audio cable') ||
                 (device.label.toLowerCase().includes('cable') && 
                  (device.label.toLowerCase().includes('virtual') || 
                   device.label.toLowerCase().includes('vb') ||
                   device.label.toLowerCase().includes('output') ||
                   device.label.toLowerCase().includes('input'))) ||
                 device.label.toLowerCase().includes('voicemeeter'))
            );

            if (vbCableDevice) {
                console.log(`‚úÖ –ù–∞–π–¥–µ–Ω–æ VB Cable —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: ${vbCableDevice.label}`);
                
                const constraints = {
                    audio: {
                        deviceId: { exact: vbCableDevice.deviceId },
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: false,
                        sampleRate: this.sampleRate,
                        channelCount: 1
                    }
                };
                
                console.log('–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ VB Cable —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏:', constraints);
                
                this.vbCableStream = await navigator.mediaDevices.getUserMedia(constraints);

                // Test the stream
                const tracks = this.vbCableStream.getAudioTracks();
                if (tracks.length > 0) {
                    const track = tracks[0];
                    console.log('‚úÖ VB Cable —Ç—Ä–µ–∫ –ø–æ–ª—É—á–µ–Ω:');
                    console.log('  - Label:', track.label);
                    console.log('  - Enabled:', track.enabled);
                    console.log('  - Ready State:', track.readyState);
                    console.log('  - Settings:', track.getSettings());
                    
                    // Check if track is actually receiving audio
                    const trackSettings = track.getSettings();
                    if (trackSettings.sampleRate) {
                        console.log(`‚úÖ VB Cable —Å–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω: ${trackSettings.sampleRate}Hz, ${trackSettings.channelCount} –∫–∞–Ω–∞–ª–æ–≤`);
                    }
                    
                    // Force track to be enabled
                    track.enabled = true;
                }

                this.setupAudioRecording(this.vbCableStream, 'P1');
                console.log('‚úÖ VB Cable capture started (P1)');
                
                // Add a test to see if we're actually getting audio data
                setTimeout(() => this.testVBCableAudio(), 2000);
                
                // Show success notification
                window.showNotification && window.showNotification('VB Cable –ø–æ–¥–∫–ª—é—á–µ–Ω —É—Å–ø–µ—à–Ω–æ!', 'success');
                
            } else {
                console.warn('‚ö†Ô∏è VB Cable —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ');
                console.warn('–î–æ—Å—Ç—É–ø–Ω—ã–µ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:');
                audioInputs.forEach(device => {
                    console.warn(`  - ${device.label}`);
                });
                
                // Try alternative approach - look for any device that might be VB Cable
                // But be more conservative to avoid false positives
                const possibleVBDevices = audioInputs.filter(device => 
                    (device.label.toLowerCase().includes('line') && 
                     device.label.toLowerCase().includes('in')) ||
                    device.label.toLowerCase().includes('stereo mix') ||
                    (device.label.toLowerCase().includes('mix') &&
                     !device.label.toLowerCase().includes('microphone')) ||
                    (device.deviceId !== 'default' && 
                     device.deviceId !== 'communications' &&
                     !device.label.toLowerCase().includes('microphone') &&
                     !device.label.toLowerCase().includes('mic'))
                );
                
                if (possibleVBDevices.length > 0) {
                    console.warn('üîç –í–æ–∑–º–æ–∂–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (–ù–ï VB Cable):');
                    possibleVBDevices.forEach((device, index) => {
                        console.warn(`  ${index + 1}. ${device.label} (ID: ${device.deviceId.substring(0, 20)}...)`);
                    });
                    
                    // Try the first candidate but warn user it's not a real VB Cable
                    if (possibleVBDevices[0]) {
                        console.log('üîÑ –ü—Ä–æ–±—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (–ù–ï VB Cable):', possibleVBDevices[0].label);
                        try {
                            const constraints = {
                                audio: {
                                    deviceId: { exact: possibleVBDevices[0].deviceId },
                                    echoCancellation: false,
                                    noiseSuppression: false,
                                    autoGainControl: false,
                                    sampleRate: this.sampleRate,
                                    channelCount: 1
                                }
                            };
                            
                            this.vbCableStream = await navigator.mediaDevices.getUserMedia(constraints);
                            this.setupAudioRecording(this.vbCableStream, 'P1');
                            console.log('‚ö†Ô∏è –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–æ (–ù–ï VB Cable):', possibleVBDevices[0].label);
                            console.warn('‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–æ –Ω–µ –Ω–∞—Å—Ç–æ—è—â–∏–π VB Cable! –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω.');
                            setTimeout(() => this.testVBCableAudio(), 2000);
                            
                            // Show warning notification
                            window.showNotification && window.showNotification(`–ü–æ–¥–∫–ª—é—á–µ–Ω–æ ${possibleVBDevices[0].label} (–ù–ï VB Cable)`, 'warning');
                        } catch (altError) {
                            console.warn('‚ùå –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –Ω–µ –ø–æ–¥–æ—à–ª–æ:', altError.message);
                        }
                    }
                }
                
                // Show warning notification
                window.showNotification && window.showNotification('VB Cable –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω', 'warning');
            }
        } catch (error) {
            console.error('‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ VB Cable:', error);
            console.error('–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:', {
                name: error.name,
                message: error.message,
                stack: error.stack
            });
            
            // Don't throw - continue with just microphone
            this.showVBCableError(error);
        }
    }

    testVBCableAudio() {
        if (!this.vbCableStream || !this.p1Analyser) {
            console.warn('‚ö†Ô∏è VB Cable –ø–æ—Ç–æ–∫ –∏–ª–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è');
            return;
        }
        
        console.log('üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞ VB Cable...');
        
        let testDuration = 8000; // 8 seconds
        let sampleCount = 0;
        let totalLevel = 0;
        let maxLevel = 0;
        let activeSamples = 0; // Count of samples with audio activity
        
        const testInterval = setInterval(() => {
            if (this.p1Analyser && this.p1DataArray) {
                this.p1Analyser.getByteTimeDomainData(this.p1DataArray);
                let sum = 0;
                let peakSample = 0;
                
                for (let i = 0; i < this.p1DataArray.length; i++) {
                    const sample = Math.abs((this.p1DataArray[i] - 128) / 128);
                    sum += sample * sample;
                    peakSample = Math.max(peakSample, sample);
                }
                
                const rms = Math.sqrt(sum / this.p1DataArray.length);
                const level = rms * 100;
                
                totalLevel += level;
                sampleCount++;
                maxLevel = Math.max(maxLevel, level);
                
                // Count samples with significant audio activity
                if (level > 0.5) {
                    activeSamples++;
                }
                
                // Real-time feedback every second
                if (sampleCount % 10 === 0) {
                    const currentAvg = totalLevel / sampleCount;
                    console.log(`üîä VB Cable —Ç–µ—Å—Ç - –û–±—Ä–∞–∑–µ—Ü ${sampleCount}: —Ç–µ–∫—É—â–∏–π=${level.toFixed(2)}%, —Å—Ä–µ–¥–Ω–∏–π=${currentAvg.toFixed(2)}%, –º–∞–∫—Å–∏–º—É–º=${maxLevel.toFixed(2)}%`);
                }
            }
        }, 100);
        
        setTimeout(() => {
            clearInterval(testInterval);
            const avgLevel = sampleCount > 0 ? totalLevel / sampleCount : 0;
            const activityRate = sampleCount > 0 ? (activeSamples / sampleCount) * 100 : 0;
            
            console.log('üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞ VB Cable:');
            console.log(`  - –°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å: ${avgLevel.toFixed(2)}%`);
            console.log(`  - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å: ${maxLevel.toFixed(2)}%`);
            console.log(`  - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–∑—Ü–æ–≤: ${sampleCount}`);
            console.log(`  - –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ: ${activityRate.toFixed(1)}% –æ–±—Ä–∞–∑—Ü–æ–≤`);
            
            if (maxLevel < 0.5) {
                console.warn('‚ùå VB Cable –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª');
                console.warn('üìã Checklist –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏:');
                console.warn('  1. VB Cable –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–∞–∫ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ (Zoom/Meet)');
                console.warn('  2. VB Cable —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ');
                console.warn('  3. –ê—É–¥–∏–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ (–≥–æ–≤–æ—Ä–∏—Ç –ª–∏ –∫—Ç–æ-—Ç–æ –≤ Zoom/Meet?)');
                console.warn('  4. –ì—Ä–æ–º–∫–æ—Å—Ç—å VB Cable –Ω–µ –Ω–∞ –Ω—É–ª–µ');
                console.warn('  5. –ü—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ –≤—ã–±—Ä–∞–Ω–æ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤ —Å–∏—Å—Ç–µ–º–µ?');
                
                window.showNotification && window.showNotification('VB Cable –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç –∞—É–¥–∏–æ! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.', 'error');
            } else if (maxLevel > 0.5 && maxLevel < 5) {
                console.log('‚ö†Ô∏è VB Cable –ø–æ–ª—É—á–∞–µ—Ç —Å–ª–∞–±—ã–π —Å–∏–≥–Ω–∞–ª');
                console.log('üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:');
                console.log('  - –£–≤–µ–ª–∏—á—å—Ç–µ –≥—Ä–æ–º–∫–æ—Å—Ç—å –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ –∞—É–¥–∏–æ');
                console.log('  - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –≤ Zoom/Meet');
                console.log('  - –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≥–æ–≤–æ—Ä—è—â–∏–π –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –±–ª–∏–∑–∫–æ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É');
                
                window.showNotification && window.showNotification('VB Cable —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ —Å–∏–≥–Ω–∞–ª —Å–ª–∞–±—ã–π', 'warning');
            } else {
                console.log('‚úÖ VB Cable –ø–æ–ª—É—á–∞–µ—Ç —Ö–æ—Ä–æ—à–∏–π –∞—É–¥–∏–æ —Å–∏–≥–Ω–∞–ª');
                console.log(`üéØ –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: ${activityRate.toFixed(1)}% –≤—Ä–µ–º–µ–Ω–∏`);
                
                if (activityRate < 10) {
                    console.log('üí¨ –ü–æ–¥—Å–∫–∞–∑–∫–∞: –í–æ–∑–º–æ–∂–Ω–æ, —Å–µ–π—á–∞—Å –Ω–∏–∫—Ç–æ –Ω–µ –≥–æ–≤–æ—Ä–∏—Ç. –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ.');
                }
                
                window.showNotification && window.showNotification('VB Cable —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!', 'success');
            }
            
            // Start continuous monitoring for ongoing feedback
            this.startContinuousMonitoring();
            
        }, testDuration);
    }

    startContinuousMonitoring() {
        if (this.continuousMonitorInterval) {
            clearInterval(this.continuousMonitorInterval);
        }
        
        console.log('üîÑ –ó–∞–ø—É—Å–∫ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ VB Cable...');
        
        let lastActivityTime = Date.now();
        let silentDuration = 0;
        
        this.continuousMonitorInterval = setInterval(() => {
            if (!this.p1Analyser || !this.p1DataArray) return;
            
            this.p1Analyser.getByteTimeDomainData(this.p1DataArray);
            let sum = 0;
            
            for (let i = 0; i < this.p1DataArray.length; i++) {
                const sample = Math.abs((this.p1DataArray[i] - 128) / 128);
                sum += sample * sample;
            }
            
            const rms = Math.sqrt(sum / this.p1DataArray.length);
            const level = rms * 100;
            
            if (level > 0.5) {
                lastActivityTime = Date.now();
                silentDuration = 0;
            } else {
                silentDuration = Date.now() - lastActivityTime;
            }
            
            // Alert if silent for too long (5 minutes)
            if (silentDuration > 300000 && silentDuration < 310000) {
                console.warn('‚ö†Ô∏è VB Cable –º–æ–ª—á–∏—Ç —É–∂–µ 5 –º–∏–Ω—É—Ç. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –∞—É–¥–∏–æ.');
                window.showNotification && window.showNotification('VB Cable –¥–æ–ª–≥–æ –º–æ–ª—á–∏—Ç - –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∞—É–¥–∏–æ', 'warning');
            }
            
            // Update current levels for UI
            this.currentLevels.p1 = level;
            
        }, 2000); // Check every 2 seconds
    }

    stopContinuousMonitoring() {
        if (this.continuousMonitorInterval) {
            clearInterval(this.continuousMonitorInterval);
            this.continuousMonitorInterval = null;
            console.log('‚èπÔ∏è –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ VB Cable –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω');
        }
    }

    showVBCableError(error) {
        // Create error notification in UI if possible
        if (typeof window !== 'undefined' && window.showNotification) {
            window.showNotification('–û—à–∏–±–∫–∞ VB Cable: ' + error.message, 'error');
        }
        
        // Log detailed troubleshooting info
        console.group('üîß –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ VB Cable');
        console.error('–û—à–∏–±–∫–∞:', error.message);
        console.log('–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:');
        console.log('1. VB Cable –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω');
        console.log('2. VB Cable –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–∞–∫ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤–≤–æ–¥–∞');
        console.log('3. –ù–µ—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É');
        console.log('4. VB Cable –Ω–µ –≤—ã–±—Ä–∞–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö —Å–∏—Å—Ç–µ–º—ã');
        console.log('');
        console.log('–†–µ—à–µ–Ω–∏—è:');
        console.log('1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ VB Cable —Å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–∞–π—Ç–∞');
        console.log('2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ VB Cable –∫–∞–∫ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ –∞—É–¥–∏–æ');
        console.log('3. –î–∞–π—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –≤ –±—Ä–∞—É–∑–µ—Ä–µ');
        console.log('4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–≤—É–∫–∞ –≤ —Å–∏—Å—Ç–µ–º–µ');
        console.groupEnd();
    }

    setupAudioRecording(stream, personType) {
        const mediaRecorder = new MediaRecorder(stream, {
            mimeType: 'audio/webm;codecs=opus'
        });

        // Setup audio analysis for level meters
        this.setupAudioAnalysis(stream, personType);

        const chunks = [];

        mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                chunks.push(event.data);
            }
        };

        mediaRecorder.onstop = () => {
            if (chunks.length > 0) {
                const audioBlob = new Blob(chunks, { type: 'audio/webm' });
                this.sendAudioChunk(audioBlob, personType);
                chunks.length = 0; // Clear chunks
            }
        };

        // Record in chunks
        mediaRecorder.start();
        
        const recordingInterval = setInterval(() => {
            if (this.isCapturing && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                mediaRecorder.start();
            } else {
                clearInterval(recordingInterval);
            }
        }, this.chunkDuration);

        // Store recorder reference
        if (personType === 'P1') {
            this.vbCableRecorder = { mediaRecorder, interval: recordingInterval };
        } else {
            this.micRecorder = { mediaRecorder, interval: recordingInterval };
        }
    }

    async sendAudioChunk(audioBlob, personType) {
        try {
            const formData = new FormData();
            formData.append('audio', audioBlob, `audio_${personType}_${Date.now()}.webm`);

            const endpoint = personType === 'P1' ? '/api/audio/upload/p1' : '/api/audio/upload/p2';
            
            const response = await fetch(endpoint, {
                method: 'POST',
                body: formData
            });

            if (!response.ok) {
                throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }

            const result = await response.json();
            console.log(`Audio chunk sent for ${personType}:`, result);

        } catch (error) {
            console.error(`Error sending audio chunk for ${personType}:`, error);
        }
    }

    async stopCapture() {
        if (!this.isCapturing) return;
        
        console.log('Stopping audio capture...');
        this.isCapturing = false;
        
        // Stop continuous monitoring
        this.stopContinuousMonitoring();
        
        // Stop VB Cable recording
        if (this.vbCableStream) {
            this.vbCableStream.getTracks().forEach(track => {
                track.stop();
                console.log('VB Cable track stopped');
            });
            this.vbCableStream = null;
        }
        
        // Stop microphone recording
        if (this.micStream) {
            this.micStream.getTracks().forEach(track => {
                track.stop();
                console.log('Microphone track stopped');
            });
            this.micStream = null;
        }
        
        // Stop media recorder
        if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
            this.mediaRecorder.stop();
        }
        
        console.log('Audio capture stopped');
    }

    // Get available audio devices
    async getAudioDevices() {
        try {
            const devices = await navigator.mediaDevices.enumerateDevices();
            const audioInputs = devices.filter(device => device.kind === 'audioinput');
            
            return audioInputs.map(device => ({
                deviceId: device.deviceId,
                label: device.label || 'Unknown Device',
                isVBCable: device.label.toLowerCase().includes('cable') || 
                          device.label.toLowerCase().includes('vb-audio')
            }));
        } catch (error) {
            console.error('Error getting audio devices:', error);
            return [];
        }
    }

    // Test audio input
    async testAudioInput(deviceId) {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    deviceId: deviceId,
                    echoCancellation: false,
                    noiseSuppression: false,
                    autoGainControl: false
                }
            });

            // Create audio context to analyze the stream
            const audioContext = new AudioContext();
            const source = audioContext.createMediaStreamSource(stream);
            const analyser = audioContext.createAnalyser();
            source.connect(analyser);

            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            
            return new Promise((resolve) => {
                let maxVolume = 0;
                let sampleCount = 0;
                
                const checkAudio = () => {
                    analyser.getByteFrequencyData(dataArray);
                    const volume = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
                    maxVolume = Math.max(maxVolume, volume);
                    sampleCount++;
                    
                    if (sampleCount < 50) { // Sample for ~1 second
                        requestAnimationFrame(checkAudio);
                    } else {
                        stream.getTracks().forEach(track => track.stop());
                        audioContext.close();
                        resolve({
                            deviceId,
                            maxVolume,
                            hasSignal: maxVolume > 5
                        });
                    }
                };
                
                checkAudio();
            });
        } catch (error) {
            console.error('Error testing audio input:', error);
            return { deviceId, error: error.message };
        }
    }

    // Manual audio chunk sending for testing
    async sendTestChunk(personType) {
        try {
            // Create a simple test audio blob
            const audioContext = new AudioContext();
            const buffer = audioContext.createBuffer(1, audioContext.sampleRate * 0.5, audioContext.sampleRate);
            const channelData = buffer.getChannelData(0);
            
            // Generate a simple tone
            for (let i = 0; i < channelData.length; i++) {
                channelData[i] = Math.sin(2 * Math.PI * 440 * i / audioContext.sampleRate) * 0.3;
            }
            
            // Convert to blob (simplified - in real app you'd need proper encoding)
            const testBlob = new Blob(['test audio data'], { type: 'audio/webm' });
            
            await this.sendAudioChunk(testBlob, personType);
            console.log(`Test chunk sent for ${personType}`);
            
        } catch (error) {
            console.error(`Error sending test chunk for ${personType}:`, error);
        }
    }

    setupAudioAnalysis(stream, personType) {
        try {
            if (!this.audioContext) {
                this.audioContext = new AudioContext();
            }

            const source = this.audioContext.createMediaStreamSource(stream);
            const analyser = this.audioContext.createAnalyser();
            
            analyser.fftSize = 2048;
            analyser.smoothingTimeConstant = 0.8;
            source.connect(analyser);

            const dataArray = new Uint8Array(analyser.frequencyBinCount);

            if (personType === 'P1') {
                this.p1Analyser = analyser;
                this.p1DataArray = dataArray;
            } else {
                this.p2Analyser = analyser;
                this.p2DataArray = dataArray;
            }

            console.log(`Audio analysis setup for ${personType}`);
        } catch (error) {
            console.error(`Failed to setup audio analysis for ${personType}:`, error);
        }
    }

    getAudioLevels() {
        // Calculate P1 level using time domain data for better responsiveness
        if (this.p1Analyser && this.p1DataArray) {
            this.p1Analyser.getByteTimeDomainData(this.p1DataArray);
            let p1Sum = 0;
            for (let i = 0; i < this.p1DataArray.length; i++) {
                const sample = (this.p1DataArray[i] - 128) / 128;
                p1Sum += sample * sample;
            }
            const rms = Math.sqrt(p1Sum / this.p1DataArray.length);
            this.currentLevels.p1 = Math.min(100, rms * 200); // Scale for visibility
        }

        // Calculate P2 level using time domain data for better responsiveness
        if (this.p2Analyser && this.p2DataArray) {
            this.p2Analyser.getByteTimeDomainData(this.p2DataArray);
            let p2Sum = 0;
            for (let i = 0; i < this.p2DataArray.length; i++) {
                const sample = (this.p2DataArray[i] - 128) / 128;
                p2Sum += sample * sample;
            }
            const rms = Math.sqrt(p2Sum / this.p2DataArray.length);
            this.currentLevels.p2 = Math.min(100, rms * 200); // Scale for visibility
        }

        return this.currentLevels;
    }
}

// WebSocket-based audio chunk sender
class WebSocketAudioSender {
    constructor(audioCapture) {
        this.audioCapture = audioCapture;
    }

    sendAudioChunk(audioData, personType) {
        if (this.audioCapture.ws && this.audioCapture.ws.readyState === WebSocket.OPEN) {
            this.audioCapture.ws.send(JSON.stringify({
                type: 'audio-chunk',
                person: personType,
                audioData: audioData,
                timestamp: Date.now()
            }));
        }
    }
}

// Export for use in other modules
if (typeof module !== 'undefined' && module.exports) {
    module.exports = { AudioCapture, WebSocketAudioSender };
} else {
    window.AudioCapture = AudioCapture;
    window.WebSocketAudioSender = WebSocketAudioSender;
}